{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for Neural Network is  0.9759703189790832\n",
      "The testing accuracy for Neural Network is  0.974881124664048\n",
      "time taken for mlp =  0:00:32.230618\n",
      "The training accuracy for Random Forestry is  0.9927635281820375\n",
      "The testing accuracy for Random Forestry is  0.9641306594996899\n",
      "time taken for rf =  0:01:32.864387\n",
      "MLP:\n",
      "[[ 159    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1140  121    0    0    0    0    0    0    0    0    0]\n",
      " [   0   64 1177    0   13    0    1    6    0    0    0    0]\n",
      " [   0    0    0  835    4    0    0    2    0    0    0    1]\n",
      " [   0    0    0    0  768    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    1  833    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  678    0    0    0    0    0]\n",
      " [   0    0   10    0    2    0    0  992    0    0    1    0]\n",
      " [   0    1    1    0    0    0    0    0 1022    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  654    0    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0  645    0]\n",
      " [   0    3    1    0    8    0    0    0    1    0    0  528]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       159\n",
      "          1       0.94      0.90      0.92      1261\n",
      "          2       0.90      0.93      0.92      1261\n",
      "          3       1.00      0.99      1.00       842\n",
      "          4       0.96      1.00      0.98       768\n",
      "          5       1.00      1.00      1.00       835\n",
      "          6       1.00      1.00      1.00       678\n",
      "          7       0.99      0.99      0.99      1005\n",
      "          8       1.00      1.00      1.00      1024\n",
      "          9       1.00      1.00      1.00       654\n",
      "         10       1.00      1.00      1.00       646\n",
      "         11       1.00      0.98      0.99       541\n",
      "\n",
      "avg / total       0.98      0.97      0.97      9674\n",
      "\n",
      "RF:\n",
      "[[ 159    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1113  148    0    0    0    0    0    0    0    0    0]\n",
      " [   0  197 1064    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0  842    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  768    0    0    0    0    0    0    0]\n",
      " [   1    0    0    0    0  834    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  678    0    0    0    0    0]\n",
      " [   0    0    1    0    0    0    0 1004    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0 1024    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  654    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  646    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0  541]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       159\n",
      "          1       0.85      0.88      0.87      1261\n",
      "          2       0.88      0.84      0.86      1261\n",
      "          3       1.00      1.00      1.00       842\n",
      "          4       1.00      1.00      1.00       768\n",
      "          5       1.00      1.00      1.00       835\n",
      "          6       1.00      1.00      1.00       678\n",
      "          7       1.00      1.00      1.00      1005\n",
      "          8       1.00      1.00      1.00      1024\n",
      "          9       1.00      1.00      1.00       654\n",
      "         10       1.00      1.00      1.00       646\n",
      "         11       1.00      1.00      1.00       541\n",
      "\n",
      "avg / total       0.96      0.96      0.96      9674\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Network model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Confusion marix to evaluate the model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# Evalute the speed of model\n",
    "import datetime\n",
    "\n",
    "# Exportation of  model\n",
    "import pickle\n",
    "\n",
    "import winsound\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "extracted_data = pd.read_csv(r'C:\\Users\\User\\Desktop\\Study\\Year 3\\Sem 1\\CG3002\\DanceProject\\Machine Learning\\extracted data\\extracted_dataset.csv')\n",
    "\n",
    "X = extracted_data.drop(['activity'], axis = 1)\n",
    "y = extracted_data['activity'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"The training accuracy for Neural Network is \", mlp.score(X_train, y_train))\n",
    "print(\"The testing accuracy for Neural Network is \", mlp.score(X_test, y_test))\n",
    "time_taken = end_time - start_time\n",
    "print(\"time taken for mlp = \", time_taken)\n",
    "\n",
    "# start_time = datetime.datetime.now()\n",
    "# svc = SVC()\n",
    "# svc.fit(X_train, y_train)\n",
    "# print(\"The training accuracy for Support Vector Machines is \", svc.score(X_train, y_train))\n",
    "# print(\"The testing accuracy for Support Vector Machines is \", svc.score(X_test, y_test))\n",
    "# end_time = datetime.datetime.now()\n",
    "# time_taken = end_time - start_time\n",
    "# print(\"time taken for svm = \", time_taken)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print(\"The training accuracy for Random Forestry is \", random_forest.score(X_train, y_train))\n",
    "print(\"The testing accuracy for Random Forestry is \", random_forest.score(X_test, y_test))\n",
    "end_time = datetime.datetime.now()\n",
    "time_taken = end_time - start_time\n",
    "print(\"time taken for rf = \", time_taken)\n",
    "\n",
    "predictions_mlp = mlp.predict(X_test)\n",
    "predictions_rf = random_forest.predict(X_test)\n",
    "\n",
    "print(\"MLP:\")\n",
    "print(confusion_matrix(y_test, predictions_mlp))\n",
    "print(classification_report(y_test,predictions_mlp))\n",
    "\n",
    "print(\"RF:\")\n",
    "print(confusion_matrix(y_test, random_forest.predict(X_test)))\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "\n",
    "# export model\n",
    "filename_mlp = \"Neural_Network_Model.sav\"\n",
    "pickle.dump(mlp, open(filename_mlp, 'wb'))\n",
    "\n",
    "# filename_svm = \"SVM.sav\"\n",
    "# pickle.dump(svc, open(filename_svm, 'wb'))\n",
    "\n",
    "filename_rd = \"RD.sav\"\n",
    "pickle.dump(random_forest, open(filename_rd, 'wb'))\n",
    "\n",
    "mapping = {1 : 'chicken', 2 : 'number7', 3 : 'sidestep', 4 : 'turnclap', 5 : 'wipers',\n",
    "           6 : 'numbersix', 7 : 'salute', 8 : 'mermaid', 9 : 'swing', 10 : 'cowboy', 11 : 'finisher'}\n",
    "\n",
    "print('done')\n",
    "duration = 800  # millisecond\n",
    "freq = 500  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 6 (0.041479)\n",
      "2. feature 71 (0.032173)\n",
      "3. feature 0 (0.031228)\n",
      "4. feature 89 (0.030906)\n",
      "5. feature 3 (0.028306)\n",
      "6. feature 1 (0.026690)\n",
      "7. feature 35 (0.025532)\n",
      "8. feature 53 (0.024313)\n",
      "9. feature 17 (0.023405)\n",
      "10. feature 69 (0.021941)\n",
      "11. feature 82 (0.021911)\n",
      "12. feature 18 (0.019541)\n",
      "13. feature 19 (0.019255)\n",
      "14. feature 7 (0.019204)\n",
      "15. feature 75 (0.017227)\n",
      "16. feature 57 (0.016881)\n",
      "17. feature 87 (0.016425)\n",
      "18. feature 64 (0.016370)\n",
      "19. feature 76 (0.015727)\n",
      "20. feature 39 (0.015508)\n",
      "21. feature 74 (0.015016)\n",
      "22. feature 44 (0.014882)\n",
      "23. feature 51 (0.014820)\n",
      "24. feature 58 (0.014662)\n",
      "25. feature 4 (0.014355)\n",
      "26. feature 77 (0.014115)\n",
      "27. feature 80 (0.014049)\n",
      "28. feature 62 (0.013737)\n",
      "29. feature 45 (0.013265)\n",
      "30. feature 24 (0.013212)\n",
      "31. feature 12 (0.012865)\n",
      "32. feature 63 (0.012359)\n",
      "33. feature 59 (0.011517)\n",
      "34. feature 46 (0.011297)\n",
      "35. feature 28 (0.011260)\n",
      "36. feature 81 (0.011221)\n",
      "37. feature 70 (0.010935)\n",
      "38. feature 56 (0.010810)\n",
      "39. feature 40 (0.010701)\n",
      "40. feature 38 (0.010556)\n",
      "41. feature 34 (0.010303)\n",
      "42. feature 66 (0.010263)\n",
      "43. feature 88 (0.010027)\n",
      "44. feature 72 (0.009444)\n",
      "45. feature 48 (0.008967)\n",
      "46. feature 9 (0.008897)\n",
      "47. feature 54 (0.008856)\n",
      "48. feature 60 (0.008581)\n",
      "49. feature 42 (0.008537)\n",
      "50. feature 41 (0.008511)\n",
      "51. feature 52 (0.008494)\n",
      "52. feature 33 (0.008265)\n",
      "53. feature 78 (0.008175)\n",
      "54. feature 85 (0.006547)\n",
      "55. feature 2 (0.006465)\n",
      "56. feature 10 (0.006456)\n",
      "57. feature 67 (0.006411)\n",
      "58. feature 55 (0.006322)\n",
      "59. feature 20 (0.006310)\n",
      "60. feature 84 (0.006155)\n",
      "61. feature 79 (0.006089)\n",
      "62. feature 25 (0.006030)\n",
      "63. feature 49 (0.005913)\n",
      "64. feature 13 (0.005742)\n",
      "65. feature 83 (0.005468)\n",
      "66. feature 73 (0.005451)\n",
      "67. feature 65 (0.005413)\n",
      "68. feature 14 (0.005318)\n",
      "69. feature 26 (0.005215)\n",
      "70. feature 21 (0.005213)\n",
      "71. feature 22 (0.005024)\n",
      "72. feature 61 (0.004811)\n",
      "73. feature 68 (0.004489)\n",
      "74. feature 36 (0.004353)\n",
      "75. feature 47 (0.004196)\n",
      "76. feature 86 (0.003959)\n",
      "77. feature 37 (0.003542)\n",
      "78. feature 43 (0.003530)\n",
      "79. feature 27 (0.003237)\n",
      "80. feature 32 (0.003163)\n",
      "81. feature 5 (0.003120)\n",
      "82. feature 11 (0.002857)\n",
      "83. feature 15 (0.002747)\n",
      "84. feature 31 (0.002367)\n",
      "85. feature 30 (0.002227)\n",
      "86. feature 16 (0.002222)\n",
      "87. feature 50 (0.002160)\n",
      "88. feature 23 (0.001838)\n",
      "89. feature 8 (0.001557)\n",
      "90. feature 29 (0.001105)\n",
      "mean: 0.242911\n",
      "max: 0.149097\n",
      "iqr: 0.173546\n",
      "mad: 0.216533\n",
      "median: 0.217912\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "importances = random_forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in random_forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "importance_mean = 0\n",
    "importance_max = 0\n",
    "importance_iqr = 0\n",
    "importance_mad = 0\n",
    "importance_std = 0\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    if (indices[f] < 18):\n",
    "        importance_mean += importances[indices[f]]\n",
    "    elif (indices[f] < 36):\n",
    "        importance_max += importances[indices[f]]\n",
    "    elif (indices[f] < 54):\n",
    "        importance_iqr += importances[indices[f]]\n",
    "    elif (indices[f] < 72):\n",
    "        importance_mad += importances[indices[f]]\n",
    "    elif (indices[f] < 90):\n",
    "        importance_std += importances[indices[f]]\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "print(\"mean: %f\" %(importance_mean))\n",
    "print(\"max: %f\" %(importance_max))\n",
    "print(\"iqr: %f\" %(importance_iqr))\n",
    "print(\"mad: %f\" %(importance_mad))\n",
    "print(\"median: %f\" %(importance_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
